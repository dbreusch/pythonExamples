{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize model \"bias\" for all scenarios\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom modules for working with model and AWS data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as ticker\n",
    "# from matplotlib.lines import Line2D\n",
    "# from matplotlib.text import Text\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import Model\n",
    "from GCNet import GCNet\n",
    "# from plotUtils import PlotUtils\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global vars\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcCutoff = 50\n",
    "Syr = 1996\n",
    "Eyr = 2005\n",
    "yrRange = (Syr,Eyr)\n",
    "yrRangeAWS = (Syr,Eyr)\n",
    "subStr = \"Jul\"\n",
    "monSub = [7]\n",
    "\n",
    "biasColumns = ['ERAI',     'WRF_ERAI', \\\n",
    "               'LE_Hist',  'WRF_LE_Hist', \\\n",
    "               'LE_RCP85', 'WRF_LE_RCP85', \\\n",
    "               'LW',       'WRF_LW', \\\n",
    "               'Future RCP85', 'Future LW', \n",
    "               'Future WRF RCP85', 'Future WRF LW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: subset a variable by years, months, QC\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetData( X, yrRange = None, monRange = None, qcFunc = None, qcLevel = None, qcIX = None):\n",
    "    \"\"\"\n",
    "        yrRange = (year1, year2), i.e., a range of years\n",
    "        monRange = (m1, m2, m3...), i.e., a list of explicit month numbers\n",
    "        qcFunc = function handle for qcStats\n",
    "        qcLevel = x, i.e., a percent cutoff\n",
    "        qcIX = existing index for QC slicing\n",
    "    \"\"\"\n",
    "\n",
    "    # first, subset by year range\n",
    "    if yrRange is not None:\n",
    "        yrStart = yrRange[0]\n",
    "        yrEnd = yrRange[1]\n",
    "        yearSub = range( yrStart, yrEnd+1 )\n",
    "        Xnew = X.loc[ X['year'].isin(yearSub) ]\n",
    "        X = Xnew\n",
    "\n",
    "    # second, subset by month range\n",
    "    if monRange is not None:\n",
    "        Xnew = X.loc[ X['month'].isin(monRange) ]\n",
    "        X = Xnew\n",
    "\n",
    "    # third, subset by data quality\n",
    "    if qcLevel is not None:\n",
    "        if qcIX is None:  # create a new QC index\n",
    "            qcPct = qcFunc( X.iloc[:,:-2] )\n",
    "            qcIX = qcPct > qcLevel\n",
    "\n",
    "        Xtemp = X.iloc[:,:-2]  # temporarily drop time, year and month columns\n",
    "        Xbest = Xtemp.iloc[:,qcIX]\n",
    "        Xbest['month'] = X['month']  # restore month column\n",
    "        X = Xbest\n",
    "\n",
    "    # drop sites with no valid data\n",
    "    Xvalid = X.dropna(axis='columns',how='all')\n",
    "    \n",
    "    # return data subset and the QC index used\n",
    "    return ( Xvalid, qcIX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load AWS metadata\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "metaFN = \"erai/site_info.nc\"\n",
    "gcnetDir = home+\"/Documents/GCNet/current\"\n",
    "dataFN = gcnetDir+\"/gcnet.allStationData_d_365.nc\"\n",
    "A = GCNet( metaFN, dataFN )\n",
    "A.loadMeta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read AWS time and data, add columns for \"year\" and \"month\"\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hours since 1900-01-01 00:00:00\n",
      "noleap\n",
      "RHS: Resetting value 18.121666\n",
      "LHS: Resetting value 14.764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbr/python_modules/GCNet.py:149: RuntimeWarning: invalid value encountered in greater\n",
      "  Y = np.array( X )\n",
      "/Users/dbr/python_modules/GCNet.py:97: RuntimeWarning: invalid value encountered in greater\n",
      "  Xqc = np.where( X > 20., np.nan, X )\n",
      "/Users/dbr/python_modules/GCNet.py:151: RuntimeWarning: invalid value encountered in greater\n",
      "  Yqc = np.where( Yqc > 1.e36, np.nan, Yqc )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time = A.loadData( \"time\", True )\n",
    "Taws = A.loadData( \"AirT1\", True )\n",
    "awsCols = Taws.columns.values\n",
    "# print awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Taws['year'] = Taws[\"Time\"].apply( lambda Taws : \n",
    "                                    datetime(year=Taws.year, month=Taws.month, day=Taws.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Taws['month'] = Taws[\"Time\"].apply( lambda Taws : \n",
    "                                    datetime(year=Taws.year, month=Taws.month, day=Taws.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Taws = Taws.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare ERA Interim\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d dataset\n",
      "Index([u'Swiss Camp', u'Crawford Point1', u'Humboldt', u'Summit', u'Tunu-N',\n",
      "       u'DYE-2', u'JAR1', u'Saddle', u'NASA-E', u'NASA-SE', u'JAR2', u'month'],\n",
      "      dtype='object')\n",
      "Index([u'Swiss Camp', u'Crawford Point1', u'Humboldt', u'Summit', u'Tunu-N',\n",
      "       u'DYE-2', u'JAR1', u'Saddle', u'NASA-E', u'NASA-SE', u'JAR2', u'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "suff = \"19960101-20171231\"\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"erai/erai_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"erai/erai_geog_sub.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# #  interpolated data\n",
    "# modelFN = \"erai/erai_tas_interp_\"+suff+\".nc\"\n",
    "# Mint = Model(\"erai/erai_geog_sub.nc\", modelFN)\n",
    "# Mint.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "print TawsValid.columns\n",
    "print TmodelValid.columns\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataframe for results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "awsNames = TawsValid.columns\n",
    "dfBias = pd.DataFrame(columns=biasColumns, index=awsNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for ERAI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'ERAI' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare WRF(ERA Interim)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d dataset\n"
     ]
    }
   ],
   "source": [
    "suff = \"1986-2015\"\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"gis_erai/wrf_erai_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"gis_erai/wrf_geog.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for WRF(ERAI)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'WRF_ERAI' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare CESM LE Historical\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d dataset\n"
     ]
    }
   ],
   "source": [
    "ens = -1  # ensemble average (and because it's the mean, results will be the same for \"all\" data!)\n",
    "\n",
    "suff = str(Syr)+\"0101-\"+str(Eyr)+\"1231\"\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"cesmle/cesmle_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"cesmle/cesmle_geog_sub.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for CESM LE Historical\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'LE_Hist' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare WRF(CESM LE Hist)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d dataset\n"
     ]
    }
   ],
   "source": [
    "suff = str(Syr)+\"-\"+str(Eyr)\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"gis_cesmle/wrf_cesmle_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"gis_cesmle/wrf_geog.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for WRF(CESM LE Hist)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'WRF_LE_Hist' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare CESM LE RCP85\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d dataset\n"
     ]
    }
   ],
   "source": [
    "Syr = 2071\n",
    "Eyr = 2080\n",
    "yrRange = (Syr,Eyr)\n",
    "suff = str(Syr)+\"0101-\"+str(Eyr)+\"1231\"\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"cesmle/cesmle_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"cesmle/cesmle_geog_sub.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for CESM LE RCP85\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'LE_RCP85' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare WRF(CESM LE RCP85)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d dataset\n"
     ]
    }
   ],
   "source": [
    "suff = str(Syr)+\"-\"+str(Eyr)\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"gis_cesmle/wrf_cesmle_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"gis_cesmle/wrf_geog.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for WRF(CESM LE RCP85)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'WRF_LE_RCP85' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare CESM LW\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d dataset\n"
     ]
    }
   ],
   "source": [
    "suff = str(Syr)+\"0101-\"+str(Eyr)+\"1231\"\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"cesmlw/cesmlw_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"cesmlw/cesmlw_geog_sub.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for CESM LW\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'LW' ] = bias    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare WRF(CESM LW)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d dataset\n"
     ]
    }
   ],
   "source": [
    "suff = str(Syr)+\"-\"+str(Eyr)\n",
    "\n",
    "# closest point data\n",
    "modelFN = \"gis_cesmlw/wrf_cesmlw_tas_closest_\"+suff+\".nc\"\n",
    "Mcl = Model(\"gis_cesmlw/wrf_geog.nc\", modelFN)\n",
    "Mcl.loadMeta()\n",
    "\n",
    "# geography\n",
    "minLon = -70 + 360\n",
    "maxLon = -15 + 360\n",
    "minLat = 58\n",
    "maxLat = 86.5\n",
    "Mcl.setDomain( (minLat, maxLat, minLon, maxLon) )\n",
    "\n",
    "# variable\n",
    "varName = \"tas\"\n",
    "\n",
    "srcFile = \"Closest\"\n",
    "timeModel = Mcl.loadData( \"time\", True )\n",
    "Tmodel1 = Mcl.loadData( varName, True )\n",
    "Tmodel1.columns = awsCols\n",
    "\n",
    "# add column with just the year (for subsetting later)\n",
    "Tmodel1['year'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).year)\n",
    "# add column with just the month (for subsetting later)\n",
    "Tmodel1['month'] = Tmodel1[\"Time\"].apply( lambda Tmodel1 : \n",
    "                                    datetime(year=Tmodel1.year, month=Tmodel1.month, day=Tmodel1.day).month)\n",
    "\n",
    "# drop column 1 (Time)\n",
    "Tmodel1 = Tmodel1.iloc[:,1:]\n",
    "\n",
    "# create comparison datasets (dataframes)\n",
    "TawsValid, qcIX = subsetData( Taws, yrRangeAWS, monSub, A.qcStats, qcCutoff )\n",
    "TmodelValid, _ = subsetData( Tmodel1, yrRange, monSub, A.qcStats, qcCutoff, qcIX)\n",
    "\n",
    "# drop the month column, no longer needed\n",
    "TawsValid   = TawsValid.iloc[:,:-1]\n",
    "TmodelValid = TmodelValid.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias for WRF(CESM LE RCP85)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bias = []\n",
    "for aws in awsNames:\n",
    "    mn1 = np.mean(TawsValid[aws])\n",
    "    mn2 = np.mean(TmodelValid[aws])\n",
    "    bias.append( mn2 - mn1 )\n",
    "dfBias[ 'WRF_LW' ] = bias    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERAI                2.01\n",
      "WRF_ERAI           -0.57\n",
      "LE_Hist            -0.47\n",
      "WRF_LE_Hist        -0.24\n",
      "LE_RCP85            4.67\n",
      "WRF_LE_RCP85        3.03\n",
      "LW                  1.42\n",
      "WRF_LW              0.38\n",
      "Future RCP85        5.15\n",
      "Future LW           1.89\n",
      "Future WRF RCP85    3.27\n",
      "Future WRF LW       0.62\n",
      "dtype: float64\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "dfBias['Future RCP85'] = dfBias['LE_RCP85'] - dfBias['LE_Hist']\n",
    "dfBias['Future LW'] = dfBias['LW'] - dfBias['LE_Hist']\n",
    "dfBias['Future WRF RCP85'] = dfBias['WRF_LE_RCP85'] - dfBias['WRF_LE_Hist']\n",
    "dfBias['Future WRF LW'] = dfBias['WRF_LW'] - dfBias['WRF_LE_Hist']\n",
    "\n",
    "# calculate average across stations for each statistic\n",
    "dfBiasAvg = dfBias.mean()\n",
    "print dfBiasAvg\n",
    "print len(dfBiasAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERAI</th>\n",
       "      <th>WRF_ERAI</th>\n",
       "      <th>LE_Hist</th>\n",
       "      <th>WRF_LE_Hist</th>\n",
       "      <th>LE_RCP85</th>\n",
       "      <th>WRF_LE_RCP85</th>\n",
       "      <th>LW</th>\n",
       "      <th>WRF_LW</th>\n",
       "      <th>Future RCP85</th>\n",
       "      <th>Future LW</th>\n",
       "      <th>Future WRF RCP85</th>\n",
       "      <th>Future WRF LW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Swiss Camp</th>\n",
       "      <td>2.24</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>5.13</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>6.07</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawford Point1</th>\n",
       "      <td>2.39</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humboldt</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.53</td>\n",
       "      <td>5.06</td>\n",
       "      <td>2.08</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summit</th>\n",
       "      <td>1.42</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunu-N</th>\n",
       "      <td>2.41</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.65</td>\n",
       "      <td>4.21</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>1.72</td>\n",
       "      <td>5.54</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYE-2</th>\n",
       "      <td>0.72</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.35</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAR1</th>\n",
       "      <td>3.55</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.38</td>\n",
       "      <td>1.76</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saddle</th>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1.47</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASA-E</th>\n",
       "      <td>2.88</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.08</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1.84</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASA-SE</th>\n",
       "      <td>1.94</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAR2</th>\n",
       "      <td>2.45</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.85</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ERAI  WRF_ERAI  LE_Hist  WRF_LE_Hist  LE_RCP85  WRF_LE_RCP85  \\\n",
       "Swiss Camp       2.24     -1.19    -0.94        -0.50      5.13          1.53   \n",
       "Crawford Point1  2.39     -0.21     0.78         0.36      4.77          3.45   \n",
       "Humboldt         1.20      0.91    -1.57         1.02      3.49          4.18   \n",
       "Summit           1.42     -1.19    -2.35        -1.12      3.24          4.31   \n",
       "Tunu-N           2.41      0.98    -2.89         0.83      2.65          4.21   \n",
       "DYE-2            0.72     -1.37    -1.91        -1.01      2.84          2.35   \n",
       "JAR1             3.55     -0.86     4.20         0.03      9.38          1.76   \n",
       "Saddle           0.93     -1.53    -1.57        -1.38      3.15          2.52   \n",
       "NASA-E           2.88      1.06    -0.11         0.78      5.67          5.08   \n",
       "NASA-SE          1.94     -1.30    -1.08        -1.34      3.67          2.79   \n",
       "JAR2             2.45     -1.55     2.23        -0.28      7.42          1.20   \n",
       "\n",
       "                   LW  WRF_LW  Future RCP85  Future LW  Future WRF RCP85  \\\n",
       "Swiss Camp       1.07   -0.16          6.07       2.01              2.03   \n",
       "Crawford Point1  2.00    0.80          3.99       1.22              3.08   \n",
       "Humboldt         0.52    1.53          5.06       2.08              3.16   \n",
       "Summit          -0.56   -0.22          5.60       1.79              5.44   \n",
       "Tunu-N          -0.78    1.72          5.54       2.11              3.38   \n",
       "DYE-2           -0.41   -0.34          4.75       1.50              3.36   \n",
       "JAR1             6.82    0.31          5.19       2.62              1.73   \n",
       "Saddle          -0.10   -0.69          4.72       1.47              3.89   \n",
       "NASA-E           1.72    1.86          5.78       1.84              4.31   \n",
       "NASA-SE          0.48   -0.62          4.76       1.56              4.13   \n",
       "JAR2             4.85   -0.06          5.19       2.62              1.48   \n",
       "\n",
       "                 Future WRF LW  \n",
       "Swiss Camp                0.34  \n",
       "Crawford Point1           0.44  \n",
       "Humboldt                  0.51  \n",
       "Summit                    0.90  \n",
       "Tunu-N                    0.89  \n",
       "DYE-2                     0.67  \n",
       "JAR1                      0.28  \n",
       "Saddle                    0.69  \n",
       "NASA-E                    1.08  \n",
       "NASA-SE                   0.72  \n",
       "JAR2                      0.22  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "dfBias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a netCDF file for the bias data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = max( [ len(d) for d in stnNames])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNCFN = \"model_bias_summary.nc\"\n",
    "\n",
    "try: ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "\n",
    "ncfile = Dataset(newNCFN,mode='w',format='NETCDF4') \n",
    "ncfile.title = \"Summary of bias by model\"\n",
    "\n",
    "stnNames = dfBias.index\n",
    "nSites = len(stnNames)\n",
    "stn_dim = ncfile.createDimension('station', nSites)\n",
    "\n",
    "str_len1 = max( [ len(d) for d in stnNames])  # longest string in stnNames\n",
    "str_dim1 = ncfile.createDimension('str_dim1', str_len1)\n",
    "\n",
    "stats_dim = ncfile.createDimension('stats_dim', len(dfBiasAvg))\n",
    "\n",
    "varDesc = [ 'ERAI bias', 'WRF ERAI bias', 'CESM LE Hist bias', 'WRF CESM LE Hist bias', \\\n",
    "            'CESM LE RCP85 bias', 'WRF CESM LE RCP85 bias', 'CESM LW 1pt5degC bias', 'WRF CESM LW 1pt5degC bias', \\\n",
    "            'CESM LE RCP85 future change', 'CESM LW 1pt5degC future change', \\\n",
    "            'WRF CESM LE RCP85 future change', 'WRF CESM LW 1pt5degC future change' ]\n",
    "str_len2 = max( [ len(d) for d in varDesc])  # longest string in varDesc\n",
    "str_dim2 = ncfile.createDimension('str_dim2', str_len2)\n",
    "\n",
    "# station names\n",
    "ncVar = ncfile.createVariable('stationName', 'c', ('station','str_dim1'))\n",
    "i = 0\n",
    "stns = np.empty( shape=(nSites,str_len1), dtype='c')\n",
    "for stn in stnNames:\n",
    "    x = netCDF4.stringtochar(np.array(stn))\n",
    "    stns[i,:] = str_len1*' '\n",
    "    stns[i,:len(x)] = netCDF4.stringtochar(np.array(stn))\n",
    "    i = i + 1\n",
    "ncVar[:,:] = stns\n",
    "\n",
    "# each column of the dataframe\n",
    "varNames = dfBias.columns\n",
    "for v, vDesc in zip( varNames, varDesc ):\n",
    "    v2 = v.replace(' ','_')\n",
    "    ncVar = ncfile.createVariable(v2, np.float32, ('station'))\n",
    "    ncVar.units = \"deg C\"\n",
    "    ncVar.description = vDesc\n",
    "    ncVar.long_name = vDesc\n",
    "    ncVar[:] = list( dfBias[ v ].astype(\"float\") )\n",
    "\n",
    "# names of the dataframe columns    \n",
    "ncVar = ncfile.createVariable('statsNames', 'c', ('stats_dim','str_dim2'))\n",
    "i = 0\n",
    "statNames = np.empty( shape=(len(dfBiasAvg),str_len2), dtype='c')\n",
    "for s in varDesc:\n",
    "    x = netCDF4.stringtochar(np.array(s))\n",
    "    statNames[i,:] = str_len2*' '\n",
    "    statNames[i,:len(x)] = netCDF4.stringtochar(np.array(s))\n",
    "    i = i + 1\n",
    "ncVar[:,:] = statNames\n",
    "\n",
    "# averages of statistics\n",
    "ncVar = ncfile.createVariable('statsAvg', np.float32, ('stats_dim'))\n",
    "ncVar.units = \"deg C\"\n",
    "ncVar.description = \"Average across stations of statistical values\"\n",
    "ncVar.long_name = \"Average across stations of statistical values\"\n",
    "ncVar[:] = list(dfBiasAvg)\n",
    "\n",
    "ncfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
